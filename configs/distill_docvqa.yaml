### General ###
distill: True
result_path: "./result/docvqa"
verbose: True
log_interval: 10 # After how many steps the logger should log

### transformer parameters ###
model_id: 'naver-clova-ix/donut-base'
max_length: 128
input_size: [1280, 960] # when the input resolution differs from the pre-training setting, some weights will be newly initialized (but the model training would be okay)

### Dataset parameters ###
dataset: "./preprocessed_dataset_docvqa/" # loading datasets (from moldehub or path)
dataset_name_training: "train"
dataset_name_validate: "validation"
sort_json_key: False
align_long_axis: False

### Train parameters ###
train_batch_sizes: 2
accumulation_steps: 2
lr: !!float 3e-5
gradient_clip_val: 0.25

num_nodes: 1
num_workers: 0

warmup_steps: 10000 # 800/8*30/10, 10%
max_epochs: 30
max_steps: -1

### Validation parameters ###
val_batch_sizes: 1
val_check_interval: 0.2
limit_val_batches: 1

### Distillation parameters ###
teacher_model_path: 'result/docvqa/best_model'
decoder_layer_map: [0, 2, 3]
encoder_layer_map: [[0,1], [0,1], [0,1,2,3,4,5,6,7,8,9,10,11,12,13], [0,1]]
alpha: 1 # Weight for self-attention loss.
beta: 1 # Weight for hidden states loss.
gamma: 1 # Weight for logit-based loss.
delta: 1 # Weight for cross-attention loss.
encoder_weight: 1
decoder_weight: 1
